{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ai03dTasks\n",
    "# Machine Learning: Decision Trees\n",
    "## Training the Model\n",
    "\n",
    "**Instructions:**\n",
    "- Complete each task below by running the code cells\n",
    "- Fill in the blanks and answer questions in markdown cells\n",
    "- Save your work when finished\n",
    "- Push this file to your GitHub \"Machine Learning\" Repo under the appropriate folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Prepare the Data - we'll start fresh with the original dataset\n",
    "\n",
    "Run this cell to load and prepare the data (repeating steps from previous lessons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loaded and prepared!\n",
      "X shape: (1307, 8)\n",
      "y shape: (1307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mc_lring26\\AppData\\Local\\Temp\\ipykernel_22892\\4216363441.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['age'].fillna(df['age'].median(), inplace=True)     # Fill missing ages with median age\n",
      "C:\\Users\\mc_lring26\\AppData\\Local\\Temp\\ipykernel_22892\\4216363441.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['fare'].fillna(df['fare'].median(), inplace=True)   # Fill missing fares with median fare\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd     \n",
    "\n",
    "df = pd.read_csv(\"Titanic Dataset.csv\")     # Load the dataset into a DataFrame\n",
    "df = df[['pclass', 'survived', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]   # Keep only selected columns\n",
    "\n",
    "df['age'].fillna(df['age'].median(), inplace=True)     # Fill missing ages with median age\n",
    "df['fare'].fillna(df['fare'].median(), inplace=True)   # Fill missing fares with median fare\n",
    "df.dropna(subset=['embarked'], inplace=True)           # Drop rows that have no 'embarked' value\n",
    "\n",
    "df = pd.get_dummies(df, columns=['sex'], drop_first=True)        # Convert 'sex' to numbers (one-hot encode)\n",
    "df = pd.get_dummies(df, columns=['embarked'], drop_first=True)   # Convert 'embarked' to numbers (one-hot encode)\n",
    "\n",
    "X = df.drop('survived', axis=1)    # X = all features except the target column\n",
    "y = df['survived']                 # y = target column we want to predict\n",
    "\n",
    "print(\"✓ Data loaded and prepared!\")      # Confirmation message\n",
    "print(f\"X shape: {X.shape}\")              # Show rows and number of feature columns\n",
    "print(f\"y shape: {y.shape}\")              # Show number of rows in target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Import Required Libraries\n",
    "\n",
    "Import the libraries we'll need for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"✓ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Understand the Data Before Splitting\n",
    "\n",
    "Let's check our data before we split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total passengers: 1307\n",
      "Number of features: 8\n",
      "Feature names: ['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_male', 'embarked_Q', 'embarked_S']\n",
      "\n",
      "Survival rate: 38.10%\n",
      "Survivors: 498\n",
      "Non-survivors: 809\n"
     ]
    }
   ],
   "source": [
    "# Check the size of X and y\n",
    "print(f\"Total passengers: {len(X)}\")               # Number of rows in the dataset\n",
    "print(f\"Number of features: {X.shape[1]}\")         # How many input columns we have\n",
    "print(f\"Feature names: {X.columns.tolist()}\")      # List of all feature column names\n",
    "\n",
    "# Check survival rate\n",
    "survival_rate = y.mean()                           # Average of 0/1 gives the survival percentage\n",
    "print(f\"\\nSurvival rate: {survival_rate:.2%}\")     # Print survival rate as a percentage\n",
    "print(f\"Survivors: {y.sum()}\")                     # Count of '1' values (people who survived)\n",
    "print(f\"Non-survivors: {(y == 0).sum()}\")          # Count of '0' values (people who died)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How many total passengers are in our dataset?**\n",
    "\n",
    "A: 1307\n",
    "\n",
    "**Q: What percentage survived?**\n",
    "\n",
    "A: 38.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Split the Data\n",
    "\n",
    "Split the data into training (80%) and testing (20%) sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Perform the train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data split complete!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Use train_test_split to split the data\n",
    "# Fill in the blanks with the given answers/values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,      # X and y\n",
    "    test_size=0.2,      # 20% for testing (0.2)\n",
    "    random_state=42    # Use 42 for reproducibility\n",
    ")\n",
    "\n",
    "print(\"✓ Data split complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Verify the split sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1045 passengers\n",
      "Testing set size: 262 passengers\n",
      "\n",
      "Training percentage: 80.0%\n",
      "Testing percentage: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Check the sizes of each set\n",
    "print(f\"Training set size: {X_train.shape[0]} passengers\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} passengers\")\n",
    "print(f\"\\nTraining percentage: {X_train.shape[0] / len(X) * 100:.1f}%\")\n",
    "print(f\"Testing percentage: {X_test.shape[0] / len(X) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How many passengers are in the training set?**\n",
    "\n",
    "A: 1045\n",
    "\n",
    "**Q: How many passengers are in the testing set?**\n",
    "\n",
    "A: 262\n",
    "\n",
    "**Q: Is the split approximately 80/20?**\n",
    "\n",
    "A: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Check that features match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train columns: 8\n",
      "X_test columns: 8\n",
      "\n",
      "Columns match: True\n"
     ]
    }
   ],
   "source": [
    "# Verify X_train and X_test have the same columns\n",
    "print(f\"X_train columns: {X_train.shape[1]}\")      # Number of feature columns in training data\n",
    "print(f\"X_test columns: {X_test.shape[1]}\")        # Number of feature columns in testing data\n",
    "print(f\"\\nColumns match: {X_train.shape[1] == X_test.shape[1]}\")   # Check if the counts are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Examine the Training Data\n",
    "\n",
    "Let's look at some examples from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of X_train:\n",
      "      pclass   age  sibsp  parch     fare  sex_male  embarked_Q  embarked_S\n",
      "1294       3  28.5      0      0   16.100      True       False        True\n",
      "545        2  30.0      3      0   21.000     False       False        True\n",
      "291        1  39.0      1      1   79.650     False       False        True\n",
      "10         1  47.0      1      0  227.525      True       False       False\n",
      "147        1  28.0      0      0   42.400      True       False        True\n",
      "\n",
      "First 10 values of y_train:\n",
      "[0, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of training features\n",
    "print(\"First 5 rows of X_train:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nFirst 10 values of y_train:\")\n",
    "print(y_train.head(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Do the row indices look sequential or random?**\n",
    "\n",
    "A: random\n",
    "\n",
    "**Q: Why is it good that they're random?**\n",
    "\n",
    "A: to prevent bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5: Create the Decision Tree Model\n",
    "\n",
    "Create an instance of DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model created!\n",
      "Model type: <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Max depth: 5\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a DecisionTreeClassifier\n",
    "# Set max_depth=5 and random_state=42\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"✓ Model created!\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "print(f\"Max depth: {model.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What does max_depth=5 mean?**\n",
    "\n",
    "A: limits tree level split to 5\n",
    "\n",
    "**Q: Why do we set random_state?**\n",
    "\n",
    "A: cause the data has to start somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 6: Train the Model\n",
    "\n",
    "Now train the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model trained successfully!\n",
      "Tree depth: 5\n",
      "Number of leaves: 29\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the model using .fit()\n",
    "# Pass X_train and y_train as arguments\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"✓ Model trained successfully!\")\n",
    "print(f\"Tree depth: {model.get_depth()}\")\n",
    "print(f\"Number of leaves: {model.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How deep is the trained tree?**\n",
    "\n",
    "A: 5\n",
    "\n",
    "**Q: Is it at the maximum depth we allowed (5)?**\n",
    "\n",
    "A: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 7: Verify the Model is Trained\n",
    "\n",
    "Let's check that our model learned something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model attributes:\n",
      "Number of features: 8\n",
      "Feature names: ['pclass' 'age' 'sibsp' 'parch' 'fare' 'sex_male' 'embarked_Q'\n",
      " 'embarked_S']\n",
      "Number of outputs: 1\n",
      "Number of classes: 2\n",
      "Classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Check model attributes after training\n",
    "print(\"Model attributes:\")\n",
    "\n",
    "print(f\"Number of features: {model.n_features_in_}\")    # How many input features the model received\n",
    "print(f\"Feature names: {model.feature_names_in_}\")      # The exact names of those features\n",
    "\n",
    "print(f\"Number of outputs: {model.n_outputs_}\")         # Number of target variables (1 for our case `survivded`)\n",
    "print(f\"Number of classes: {model.n_classes_}\")         # How many categories the model predicts (0 and 1 → two classes... survived or not?)\n",
    "print(f\"Classes: {model.classes_}\")                     # Shows the actual class labels the model learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How many features did the model use?**\n",
    "\n",
    "A: 8\n",
    "\n",
    "**Q: What are the two classes (possible outcomes)?**\n",
    "\n",
    "A: Survived or died [0 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Make a Quick Test Prediction\n",
    "\n",
    "Test that the model can make predictions (we'll evaluate properly in the next lesson).\n",
    "\n",
    "## How `.fit()` and `.predict()` work\n",
    "\n",
    "**`fit()`** → trains the model\n",
    "  The model looks at the training features (X) and the correct answers (y) to learn patterns.\n",
    "\n",
    "**`predict()`** → makes guesses\n",
    "  After learning, the model uses those patterns to predict outcomes for new X data.\n",
    "\n",
    "**Simple idea:**\n",
    "`fit = learn`\n",
    "`predict = guess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions vs actual:\n",
      "Passenger 1: Predicted=0, Actual=0 ✓\n",
      "Passenger 2: Predicted=0, Actual=1 ✗\n",
      "Passenger 3: Predicted=0, Actual=0 ✓\n",
      "Passenger 4: Predicted=0, Actual=0 ✓\n",
      "Passenger 5: Predicted=0, Actual=0 ✓\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the first 5 rows in the test set\n",
    "sample_predictions = model.predict(X_test.head(5))      \n",
    "\n",
    "# Get the actual survival values for those same 5 passengers\n",
    "actual_values = y_test.head(5).tolist()                \n",
    "\n",
    "print(\"Sample predictions vs actual:\")\n",
    "\n",
    "# Loop through each pair of predicted vs actual values\n",
    "for i, (pred, actual) in enumerate(zip(sample_predictions, actual_values)):\n",
    "    result = \"✓\" if pred == actual else \"✗\"            # Check if the prediction was correct\n",
    "    print(f\"Passenger {i+1}: Predicted={pred}, Actual={actual} {result}\")   # Show comparison for each passenger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Did the model get any predictions correct?**\n",
    "\n",
    "A: all but one\n",
    "\n",
    "**Q: Can you tell from just 5 examples how good the model is?**\n",
    "\n",
    "A: it got 4/5 correct which could mean that it has at least ~80% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reflection Questions\n",
    "\n",
    "Answer these questions based on your work:\n",
    "\n",
    "**1. Why do we split data into training and testing sets?**\n",
    "\n",
    "Answer: so that you can use actual data to train the model and then test the model using different but related data instead of made up senarios.\n",
    "\n",
    "**2. What would happen if we trained on 100% of the data and tested on the same 100%?**\n",
    "\n",
    "Answer: It wouldn't show accuracy because it's using the same data it trained on so it would obviously get it right.\n",
    "\n",
    "**3. What does the .fit() method do?**\n",
    "\n",
    "Answer: trains the model on the specified data\n",
    "\n",
    "**4. What is max_depth and why is it important?**\n",
    "\n",
    "Answer: the max subdivisions on the decision tree. It prevents the model from making too many subdivisions.\n",
    "\n",
    "**5. Explain in your own words what 'training a model' means.**\n",
    "\n",
    "Answer: supplying data to a model so it can predict related information of the supplied data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lesson Complete! \n",
    "\n",
    "You've successfully trained your first machine learning model!\n",
    "\n",
    "**Summary of what you did:**\n",
    "- Split data into training (80%) and testing (20%) sets\n",
    "- Created a DecisionTreeClassifier with max_depth=5\n",
    "- Trained the model using .fit() on training data\n",
    "- Model learned patterns from 1000+ training examples\n",
    "- Model is ready to make predictions!\n",
    "\n",
    "Save this notebook and push to GitHub.\n",
    "\n",
    "**Next lesson**: Evaluate how well your model performs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
